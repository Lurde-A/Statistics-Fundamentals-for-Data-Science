                                      LINEAR REGRESSION 
GIVEN:
# Load libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
import codecademylib3
# Read in the data
codecademy = pd.read_csv('codecademy.csv')

                                      INSPECT THE DATA
  1. A dataset has been loaded for you in script.py and saved as a dataframe named codecademy. We’re imagining that this data was collected as part of an experiment to understand 
factors that contribute to learner performance on a quiz. The data contains three columns:
score: student score on a quiz
completed: the number of other content items on Codecademy that the learner has completed prior to this quiz
lesson: indicates which lesson the learner took directly before the quiz ('Lesson A' or 'Lesson B')
Take a look at this dataset by printing the first five rows.
//
print(codecademy.head())                                      RESULT:
                                                              	score	completed	lesson
                                                              0	82.7	35.0	    Lesson A
                                                              1	65.2	31.0	    Lesson A
                                                              2	55.3	33.0	    Lesson A
                                                              3	28.8	25.0	    Lesson B
                                                              4	31.2	18.0	    Lesson B

                                      MODEL THE RELATIONSHIP BETWEEN QUIZ SCORE AND NUMBER OF COMPLETED CONTENT ITEMS
  2. Plot a scatter plot of score (y-axis) against completed (x-axis) to see the relationship between quiz score and number of completed content items. Make sure to show, then clear 
the plot. Is there a relationship between these two variables, and does it appear to be linear?
//
plt.scatter(codecademy.completed, codecademy.score)
plt.show()
plt.clf()
  3. Create and fit a linear regression model that predicts score using completed as the predictor. Print out the regression coefficients.
//
model = sm.OLS.from_formula('score~completed', data=codecademy)
results = model.fit()
print(results.params)                                          RESULT:
                                                               Intercept	13.21411302117958
                                                               completed	1.306825592807168
  4. Write a one-sentence (each) interpretation of the slope and intercept that you printed out in the previous step. Make sure to comment out the interpretation so your code still runs.
//
# Intercept interpretation:
# With no other completed content items prior to the quiz the learner would score 13.214113 on it.
# Slope interpretation:
# With each additional completed content item the learner would score ~1.31 higher on the quiz.
  5. Plot the same scatter plot that you made earlier (with score on the y-axis and completed on the x-axis), but this time add the regression line on top of the plot. Make sure 
to show, then clear the plot. Do you think this line fits the data well?
//
plt.scatter(codecademy.completed, codecademy.score)
plt.plot(codecademy.completed, results.params[0]+results.params[1]*codecademy.completed)
plt.show()
plt.clf()            Visually looks like it fits the data well. 
  6. Use your model to calculate the predicted quiz score for a learner who has previously completed 20 other content items.
//
predicted_score = results.params[0] + results.params[1]*20
print(predicted_score)                                        RESULT: 39.350624877322936
  7. Calculate the fitted values for your model and save them as fitted_values.
//
fitted_values = results.predict(codecademy)
print(fitted_values.head())                                   RESULT:
                                                              0	58.953008769430454
                                                              1	53.72570639820179
                                                              2	56.33935758381612
                                                              3	45.884752841358775
                                                              4	36.736973691708606
  8. Calculate the residuals for the model and save the result as residuals.
//
residuals = codecademy.score - fitted_values
print(residuals.head())                                       RESULT:
                                                              0	23.74699123056955
                                                              1	11.474293601798216
                                                              2	-1.0393575838161198
                                                              3	-17.084752841358775
                                                              4	-5.5369736917086065
  9. Check the normality assumption for linear regression by plotting a histogram of the residuals. Make sure to show and clear the plot. Do the residuals appear to be approximately 
normally distributed?
//
plt.hist(residuals)
plt.show()
plt.clf()            Looks like the residuals are distributed normally.
  10. Check the homoscedasticity assumption for linear regression by plotting the residuals (y-axis) against the fitted values (x-axis). Do you see any patterns or is 
the homoscedasticity assumption met?
//
plt.scatter(fitted_values, residuals)
plt.show()
plt.clf()            Homoscedasticity assumption is met. No clear dependance patterns can be identified.

                                      DO LEARNERS WHO TAKE LESSONS A OR B PERFORM BETTER ON THE QUIZ?
  11. Let’s now turn our attention to the lessons column to see if learners who took different lessons scored differently on the quiz. Use sns.boxplot to create a boxplot of score 
(y-variable) for each lesson (x-variable) to see the relationship between quiz score and which lesson the learner completed immediately before taking the quiz. Make sure to show, 
then clear the plot. Does one lesson appear to do a better job than the other of preparing students for this quiz? If so, which one?
//
sns.boxplot(data=codecademy, x="lesson", y="score")
#OR
sns.boxplot(codecademy.lesson, codecademy.score)
plt.show()
plt.clf()            Visually it looks like Lesson A helps learners score higher on the quiz than Lesson B learners. 
  12. Create and fit a linear regression model that predicts score using lesson as the predictor. Print out the regression coefficients.
//
model2 = sm.OLS.from_formula('score~lesson', data=codecademy)
results2 = model2.fit()
print(results2.params)                                        RESULT:
                                                              Intercept	          59.22
                                                              lesson[T.Lesson B]	-11.64200000000001
  13. Calculate and print out the mean quiz scores for learners who took lesson A and lesson B.
      Calculate and print out the mean difference.
Can you see how these numbers relate to the intercept and slope that you printed out in the linear regression output?
//
Lesson_A_learners_mean = np.mean(codecademy.score[codecademy.lesson == "Lesson A"])
Lesson_B_learners_mean = np.mean(codecademy.score[codecademy.lesson == "Lesson B"])
print(Lesson_A_learners_mean)                                 RESULT: 59.220000000000006
print(Lesson_B_learners_mean)                                 RESULT: 47.578
print(Lesson_A_learners_mean - Lesson_B_learners_mean)        RESULT: 11.642000000000003

                                      NEXT STEPS
  Congratulations! You’ve used a simple linear model to understand how quiz scores are related to other learner actions. In this project, we’ve focused on modeling 
the relationship between quiz score and one other variable at a time (first we looked at completed, then we looked at lesson separately). The next step in linear regression is 
to model quiz scores as a function of multiple other variables at once! To get a preview of what this might look like visually, let’s try using seaborn‘s lmplot() function to plot 
a scatter plot of score vs. completed, colored by lesson. For context, the lm in lmplot() stands for “linear model”. This function will automatically plot a linear regression model 
on top of the scatter plot. The code to implement this looks like:
sns.lmplot(x = 'completed', y = 'score', hue = 'lesson', data = codecademy)
plt.show()
Note that when we include a third variable in our plot using the hue parameter (which controls the color of each point in the scatter plot), something interesting happens! All of 
a sudden, we end up with multiple regression lines.
